
```{r import, echo = FALSE}
library(readxl)
library(vegan)
soln=FALSE
# xlsx files
ham <- read_excel("ind dates flat all parameters Hamilton only FOR Kim.xlsx")

ham$area_group <- as.factor(ham$area_group)
```


# Multivariate analysis

## Introduction to multivariate analysis

In previous sections, we have discussed scenarios where there is one response variable. If we have multiple responses, $y_1$...$y_n$, and multiple predictors, $x_1$...$x_n$, then we need multivariate approaches.

These methods allow us to represent the variables or observations in a lower-dimensional space, such as a two-dimensional or three-dimensional plot, while preserving the overall structure of the data. (Dimension reduction)


*OUTLINE: "Large zooplankton such as Daphnia, large copepods or predatory Cladocera (Bythotrephes, Cercopagis, Leptodora) are much better prey for forage fishes, so changes in their populations (or shifting drivers) are of particular interest."*

**Question: What is the relationship between Daphnia and some other important environmental variables at station HH258?**

*Variables*: Daphnia biomass (mg/m3), water column temperature (°C), epilimnion temperature(°C), particulate organic nitrogen (mg/L), dissolved inorganic carbon (mg/L), particulate organic carbon (mg/L)

A good practice before running any analysis is to subset a new dataframe which contains the variables we are interested in. 

```{r, echo = TRUE}
## Select the variables interested
ham.multi <- ham[ham$Station_Acronym == "HH258",
                 c("area_group","season","Station_Acronym","Daphnia",
                    "watercolumn_temp","mean_mixing_depth_temp",
                    "PON_ECCC1m", "DIC_ECCC1m", "POC_ECCC1m")]


## Remove all rows containing NAs
ham.multi <- na.omit(ham.multi)


## Rename the columns
colnames(ham.multi) <- c("area","season","station","daphnia","column.temp",
                         "epili.temp","pon","dic","poc")
```

Now we have a dataframe containing 103 observations, all from station HH258. In this new dataframe, different seasons are represented by numeric numbers from 1 to 5. We would like to re-code them into string factors, for easier visualization in later graphics. There are many ways to do this, here we introduce using the **`factor()`** function.

```{r, echo = TRUE}
## Recode the season numeric code into factors
table(ham.multi$season)
ham.multi$season <- factor(ham.multi$season, 
                           levels = c(1, 2, 3, 4), 
                           labels = c("spring", "early summer",
                                      "late summer", "early fall"))
```


## Principle Component Analysis (PCA)

Principle component analysis is a linear transformation method that converts the original set of variables into a new set of linearly uncorrelated variables, called principal components (PCs), which are sorted in decreasing order of variance.


### Why should we use PCA?

1. Explore the relationships among multiple environmental variables. Collapse correlating variables.

2. Visualize the relationships among samples/environmental variables in a lower dimensional space.


### Correlation examination

First of all, we need to examine the correlation between our variables. We can achieve this by running a correlation test using **`cor()`** function, or creating a correlation plot using **`pairs()`** function.

```{r, echo = FALSE}
## Correlation table
cor.df <- cor(ham.multi[,4:9])
knitr::kable(cor.df)

## Correlation plot
pairs(ham.multi[,4:9], main = "Ham Data",
      pch = as.numeric(ham.multi$season), col = (ham.multi$season))
```

```{r, echo = TRUE, eval = FALSE}
## Correlation table
cor.df <- cor(ham.multi[,4:9])

## Correlation plot
pairs(ham.multi[,4:9], main = "Ham Data",
      pch = as.numeric(ham.multi$season), col = (ham.multi$season))
```

Dimension reduction techniques such PCA works the best when variables are strongly correlated with each other. From the above correlation test output and plot, we can see that some variables clearly have a linear relationship, such as water column temperature and epilimnion temperature, or water column temperature and dissolved inorganic carbon.


### PCA with standardized data

Now we can start with running our principle component analyses. PCA can be computed using various functions in R, such as **`prcomp()`** in *stats* package, **`princomp()`** in *stats* package, **`rda()`** in *vegan* package.

*Important Note: The rda() function in vegan allows users to conduct both PCA and RDA, depending on whether the data is constrained or not. When it is unconstrained (like in our example), it is running a PCA!*

Here we demonstrate using the *vegan* package, since it also allows easy visualization of our results. Keep in mind that we need to run the PCA on all columns containing continuous variables, which is column 4 - 9 in the ham.multi dataframe.

```{r, echo = TRUE}
## Run PCA analysis
pca.ham <- rda(ham.multi[,4:9], scale = TRUE) #subset for all continuous variables
```


#### Try it now: {-}

Subset a new dataframe containing the same set of variables from station HH6, and run a PCA with this data.

```{r, echo=soln, eval=TRUE}
## Select the variables interested
ham.yourmulti <- ham[ham$Station_Acronym == "HH6",
                 c("area_group","season","Station_Acronym","Daphnia",
                    "watercolumn_temp","mean_mixing_depth_temp",
                    "PON_ECCC1m", "DIC_ECCC1m", "POC_ECCC1m")]

## Remove all rows containing NAs
ham.yourmulti <- na.omit(ham.yourmulti)

## Rename the columns
colnames(ham.yourmulti) <- c("area","season","station","daphnia","column.temp",
                         "epili.temp","pon","dic","poc")

## PCA
newpca.ham <- rda(ham.yourmulti[,4:9], scale = TRUE)
```

1. How many samples (rows) do we have in this new dataframe?
2. What is the cumulative variance explained by the first two PCs?

Answers:
```{r, echo=FALSE, eval=TRUE}
# How many samples in the new dataframe
length(ham.yourmulti$area)

# Cumulative variance explained by PC1 and PC2
77.11
```


### Extract samples and variables scores in new ordination system

After completing the dimension reduction process, each sample now appears as a point in space specified by its new position along the principle component axes. There coordinates are referred to as "site scores" in rda() results, and we can access such information with the **`scores()`** function.

```{r, echo = TRUE, eval = FALSE}
scores(pca.ham, display = "sites")
```

Meanwhile, our six original variables are projected on the new principle components. They are defined as "Loadings" and are referred to as "species scores" in rda() results. This information can be obtained with the **`scores()`** function too.

```{r, echo = TRUE, eval = FALSE}
scores(pca.ham, display = "species")
```


**Remember**:

* "Sites" refer to your observations (the rows in your dataset).

* "Species" refer to your descriptors (the columns in your dataset), which are the different environmental variables.


### Screeplot

Now, let's determine how many principle components to retain for further analysis. The **`screeplot()`** function allows us to visualize the variance explained by each of the principle components. Ideally, a curve should be steep, and then bend at an "elbow", after which the curve flattens out. The first few principle components usually account for a large portion of the variance in the data, and should be retained.

```{r, echo = TRUE}
## Screeplot
screeplot(pca.ham, type = ("lines"), main = "Screeplot", pch = 16, cex = 1)
```

Meanwhile, we can also look at the proportional variance explained by each principle component. Recall that such information is available in the **`summary()`** of our PCA results. We see the first two PCs together explain roughly 76.5% of the total variance in this dataset. Along with the screeplot, we are confident that the first two PC are sufficient enough to represent our data.


### Plot ordination for PCA

After we have chosen the first two principle components, now let's start visualizing our multidimensional data in a 2-dimensional space. 

As we have seen in previous materials, there are many different methods/packages for creating plots in R. Some of these resources are listed in the "Other Resources" section at the end if you are interested. For this tutorial, we demonstrate using base R to visualize our multivariate results.

In general, plotting ordination with base R follows two steps:

1. Use **`plot()`** to create an empty canvas (You can specify the title, axes, limits, and many other features during this step).

2. Use **`points()`** to add points representing samples or variables in the new dimensions. Use **`text()`** to add labels.


**Plot 1 - Site Plot (samples)**

We can visualize the positions of our samples on the new axes (PC1 and PC2). This is the "site plot".

```{r, echo = TRUE}
# Create a blank plot
plot(pca.ham, type = "n", main = "Individuals ('sites')",
         xlab = "PC1 (50.92%)", 
         ylab = "PC2 (25.60%)", 
         ylim = c(-1.5,1.5))

# Use points() to add points
points(pca.ham, display = "sites", cex = 1) # add sites
```

What if we are interested in the seasonal patterns of our samples on the reduced dimensions? We can use the same graphing techniques, but group our dataset using different seasons. Make sure to label your seasons in the "legend".

```{r, echo = TRUE}
## Create an empty canvas
plot(pca.ham, type = "n", main = "Individuals ('sites') by season",
         xlab = "PC1 (50.92%)", 
         ylab = "PC2 (25.60%)",
         ylim = c(-1.5,1.5)) # specify the y-axis limits

## Use points() to add points
points(pca.ham, display = "sites",
       pch = as.numeric(ham.multi$season) + 14, 
       col = c(2, 3, 4, 5)[as.numeric(ham.multi$season)], 
       cex = 1) # add sites

## Legend
legend("bottomright", legend = unique(ham.multi$season),
       pch = as.numeric(unique(ham.multi$season)) + 14,
       col = c(2,3,4,5), bty = "n", cex = 1) # add legend

```


**Plot 2 - Biplot (samples and variables)**

Finally, we can visualize both "sites" (individual observations) and "species" (variables) on one graph with a biplot. This time, we use the **`biplot()`** function to do this.

```{r, echo = TRUE}
## Biplot for PCA
biplot(pca.ham,
       display = c("sites","species"), 
       type = c("text", "points"),
       main = "Biplot",
       xlab = "PC1 (50.92%)", 
       ylab = "PC2 (25.60%)")
```

**Some important points for the `biplot()` function**:

1. **`biplot()`** allows different scaling options to preserve either the Euclidean distance (in multidimensional space) among objects (sites), or the correlations/covariances between variables (species). To learn more, please refer to the [function description](https://rdrr.io/rforge/vegan/man/biplot.rda.html) or these online tutorials: [QCBS workshop - Unconstrained Ordination Scaling](https://r.qcbs.ca/workshop09/book-en/principal-component-analysis.html#condensing-data-with-principal-component-analysis); [Tutorial 14.2 - Principle Component Analysis (PCA)](https://www.flutterbys.com.au/stats/tut/tut14.2.html).

2. **`biplot()`** can also be used to show only the samples or variables, by setting `display = "sites"` or `display = "species"`. However, it does not allow further customization (such as color samples depending on a grouping factor). This is why we introduce the slightly more complicated **`plot()`** method in the previous sections.



## Non-metric multidimensional scaling (nMDS)

As we discussed earlier, PCA is a linear transformation method. It relies on the assumption of linearity and only works with continuous variables. What if we have categorical or non-linearly correlated variables? In these situations, we can another multivaraite method called non-metric multidimensional scaling (nMDS).

Unlike PCA, nMDS does not rely on the Euclidean distance. Instead, you can choose what distance measure to use. A few common measures include Jaccard for biography data or Bray-Curtis for abundance data. Dissimilarity is calculated using the distance measure for each pair of observations. These observations/points are then placed in ordination space and arranged so that the rank order of dissimilarities is reproduced as best as possible in the reduced space.

**In other words, the goal of nMDS is to represent the original position of samples (in multidimensional space) as accurately as possible using a reduced number of dimensions.**

We can use the **`metaMDS()`** function in the vegan package to conduct non-metric multidimensional scaling in R. In addition to the input dataframe, this function also requires us to specify the distance measure `distance = ?` and number of reduced dimensions `k = ?`.

```{r, echo = TRUE}
## Run nMDS
nmds.ham <- metaMDS(ham.multi[,4:9], distance = "bray", k = 2, trace = FALSE)

## Stress
nmds.ham$stress
```

From the nMDS results, we can extract the **stress**. Stress identifies how well points fit within the specified number of dimensions.

*A good rule of thumb for stress:*

* *$>0.2$ Poor (risk in interpretation)*
* *$0.1-0.2$ Fair (some distances misleading)*
* *$0.05-0.1$ Good (inferences confident)*
* *$<0.05$ Excellent representation*


### Shepard Plot

We can use a Shepard plot to learn about the distortion of representation. On the x-axis, it plots the original dissimilarity (original distances in full dimensions). On the y-axis, it plots the distances in the reduced dimensional space. Ideally, if we have a perfect fit, all the points would fall along this increasing monotonic line (red line).


```{r, echo = TRUE}
## Shepard plot
stressplot(nmds.ham, pch = 16, las = 1,
           main = "Shepard plot")
```


### Plot ordination for nMDS

No we can plot the ordination for nMDS, just like for PCA in the previous sections. The steps exactly the same. We use **`plot()`** to create an empty canvas first, then use **`points()`** to add samples/variables.

```{r, echo = TRUE}
## Create empty canvas
plot(nmds.ham, type = "n", main = "nMDS Ordination")

## Add points and legends
points(nmds.ham, display = "sites",
       pch = as.numeric(ham.multi$season) + 14,
       col = c(2, 3, 4, 5) [as.numeric(ham.multi$season)],
       cex = 1) # add sites
legend("bottomright", legend = unique(ham.multi$season),
       pch = as.numeric(unique(ham.multi$season)) + 14,
       col = c(2,3,4,5), bty = "n", cex = 1) # add legend
```

Now we can visualize the relationship between our variables and samples for each season. There is no obvious clustering of points for season groups.


## Other resources

*Multivariate analyses tutorials*

* [Building Skills in Quantitative Biology](https://www.quantitative-biology.ca/multi.html)
* [QCBS R Workshop Series - Multivariate Analyses in R](https://r.qcbs.ca/workshop09/book-en/index.html)
* [Running NMDS using 'metaMDS'(nMDS tutorial with vegan package)](https://rpubs.com/CPEL/NMDS)
* [Introduction to Ordination](https://ourcodingclub.github.io/tutorials/ordination/)
* [Starting with Non-Metric Multidimensional Scaling (NMDS)](https://www.lib.virginia.edu/data/articles/starting-non-metric-multidimensional-scaling-nmds)

*Useful R packages*

* [factoextra (for visualizing PCA results)](https://www.rdocumentation.org/packages/factoextra/versions/1.0.3)
* [learnPCA (an R package for PCA learning)](https://bryanhanson.github.io/LearnPCA/)
* [ggbiplot](https://www.rdocumentation.org/packages/ggbiplot/versions/0.55)



